// @ts-nocheck
function sleep(ms) {
  return new Promise((r)=>setTimeout(r, ms));
}
function errToString(err) {
  try {
    if (!err) return 'unknown error';
    if (typeof err === 'string') return err;
    if (typeof err.toString === 'function') return err.toString();
    return JSON.stringify(err);
  } catch  {
    try {
      return String(err);
    } catch  {
      return 'error';
    }
  }
}
async function fetchWithTimeout(url, init = {}) {
  const timeoutMs = init.timeoutMs ?? 12000;
  const ctrl = new AbortController();
  const id = setTimeout(()=>ctrl.abort(), timeoutMs);
  try {
    return await fetch(url, {
      ...init,
      signal: ctrl.signal
    });
  } finally{
    clearTimeout(id);
  }
}
async function fetchHtml(url) {
  const headers = {
    'user-agent': 'Mozilla/5.0 (compatible; LeadEnricher/1.0; +https://example.com)'
  };
  let lastErr;
  for(let attempt = 0; attempt < 2; attempt++){
    try {
      const res = await fetchWithTimeout(url, {
        headers,
        timeoutMs: 12000
      });
      if (!res.ok) throw new Error(`fetch ${url} ${res.status}`);
      // Stream and cap at ~300KB
      const reader = res.body?.getReader();
      if (!reader) return await res.text();
      const chunks = [];
      let received = 0;
      const CAP = 300 * 1024;
      while(true){
        const { done, value } = await reader.read();
        if (done) break;
        received += value?.length || 0;
        chunks.push(value);
        if (received >= CAP) break;
      }
      const combined = new Uint8Array(chunks.reduce((acc, cur)=>acc + cur.length, 0));
      let offset = 0;
      for (const c of chunks){
        combined.set(c, offset);
        offset += c.length;
      }
      return new TextDecoder('utf-8').decode(combined);
    } catch (e) {
      lastErr = e;
      if (attempt === 0) await sleep(300);
    }
  }
  throw lastErr || new Error(`fetch ${url} failed`);
}
function htmlToPlainText(html) {
  try {
    if (!html) return '';
    let out = html;
    // Strip head/noscript/script/style blocks entirely
    out = out.replace(/<head[\s\S]*?<\/head>/gi, '');
    out = out.replace(/<noscript[\s\S]*?<\/noscript>/gi, '');
    out = out.replace(/<script[\s\S]*?<\/script>/gi, '');
    out = out.replace(/<style[\s\S]*?<\/style>/gi, '');
    // Insert newlines around common block elements to preserve structure
    const blockTags = [
      'p',
      'div',
      'section',
      'article',
      'header',
      'footer',
      'main',
      'aside',
      'ul',
      'ol',
      'li',
      'table',
      'thead',
      'tbody',
      'tr',
      'td',
      'th',
      'pre',
      'code',
      'blockquote',
      'h1',
      'h2',
      'h3',
      'h4',
      'h5',
      'h6',
      'br'
    ];
    for (const t of blockTags){
      const reOpen = new RegExp(`<${t}[^>]*>`, 'gi');
      const reClose = new RegExp(`</${t}>`, 'gi');
      out = out.replace(reOpen, '\n');
      out = out.replace(reClose, '\n');
    }
    // Remove remaining tags
    out = out.replace(/<[^>]+>/g, '');
    // Decode a few common entities
    out = out.replace(/&nbsp;/g, ' ').replace(/&amp;/g, '&').replace(/&lt;/g, '<').replace(/&gt;/g, '>').replace(/&quot;/g, '"').replace(/&#39;/g, "'");
    // Collapse whitespace and limit blank lines
    out = out.replace(/[\t\f\r ]+/g, ' ');
    out = out.replace(/\n{3,}/g, '\n\n');
    return out.trim();
  } catch  {
    return html;
  }
}
// Use plain-text cleaning (no Turndown, no fallbacks)
function htmlToMarkdown(html) {
  if (!html) throw new Error('empty html');
  return htmlToPlainText(html);
}
function normalizeUrl(u) {
  try {
    const url = new URL(u);
    url.hash = '';
    return url.href;
  } catch  {
    return u;
  }
}
function extractInternalLinks(html, homeUrl) {
  const results = [];
  const home = new URL(homeUrl);
  const re = /<a\s+[^>]*href=["']([^"']+)["'][^>]*>/gi;
  let m;
  while((m = re.exec(html)) !== null){
    const href = (m[1] || '').trim();
    if (!href || href.startsWith('#') || href.startsWith('mailto:') || href.startsWith('tel:') || href.startsWith('javascript:')) continue;
    try {
      const abs = new URL(href, home).href;
      const absUrl = new URL(abs);
      if (absUrl.hostname === home.hostname) {
        results.push(normalizeUrl(abs));
      }
    } catch  {}
  }
  // de-duplicate preserving order
  const seen = new Set();
  return results.filter((u)=>seen.has(u) ? false : (seen.add(u), true));
}
async function openAiChat(key, messages) {
  console.log('openAiChat:call', {
    messagesCount: messages?.length ?? 0,
    hasKey: Boolean(key)
  });
  try {
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'content-type': 'application/json',
        authorization: `Bearer ${key}`
      },
      body: JSON.stringify({
        model: 'gpt-5-nano',
        messages
      })
    });
    if (!res.ok) {
      const body = await res.text().catch(()=>'');
      throw new Error(`openai ${res.status}: ${body.slice(0, 200)}`);
    }
    const json = await res.json();
    console.log('openAiChat:response', {
      hasChoices: Boolean(json?.choices?.length),
      model: json?.model
    });
    return json.choices?.[0]?.message?.content;
  } catch (e) {
    const msg = errToString(e);
    console.error('openAiChat:error', msg);
    throw new Error(msg);
  }
}
function extractAbstract(content) {
  if (!content) return '';
  const trimmed = content.trim();
  // Try raw JSON first
  try {
    const obj = JSON.parse(trimmed);
    if (obj && typeof obj === 'object' && typeof obj.abstract === 'string') return obj.abstract;
  } catch  {}
  // Try to find a JSON block inside code fences or text
  const match = trimmed.match(/\{[\s\S]*\}/);
  if (match) {
    try {
      const obj = JSON.parse(match[0]);
      if (obj && typeof obj === 'object' && typeof obj.abstract === 'string') return obj.abstract;
    } catch  {}
  }
  // If we didn't find valid JSON with an abstract, treat as no result
  return '';
}
function extractHeadlineFromRaw(raw) {
  try {
    if (!raw) return null;
    const obj = typeof raw === 'string' ? JSON.parse(raw) : raw;
    const cand = obj?.Headline ?? obj?.headline ?? obj?.profile?.Headline ?? obj?.profile?.headline ?? obj?.linkedin?.headline;
    if (typeof cand === 'string' && cand.trim()) return cand.trim();
    return null;
  } catch  {
    return null;
  }
}
export class WebsiteScrapeEnricher {
  supabase;
  openaiKey;
  constructor(ctx){
    this.supabase = ctx.supabase;
    this.openaiKey = ctx.openaiKey;
    console.log('WebsiteScrapeEnricher:init', {
      hasOpenAIKey: Boolean(this.openaiKey)
    });
  }
  async enrich({ leadId }) {
    const t0 = Date.now();
    console.log('WebsiteScrapeEnricher:enrich:start', {
      leadId
    });
    const { lead, campaign } = await this.loadLeadAndCampaign(leadId);
    const { base, homepage } = this.computeBaseAndHomepage(lead);
    const urls = await this.discoverUrls(homepage);
    const pageSummaries = await this.summarizeTopPages(urls, campaign, lead, base, 3);
    if (pageSummaries.length === 0) throw new Error('no page summaries from website');
    const iceBreaker = await this.generateIcebreaker(campaign, lead, pageSummaries);
    console.log('WebsiteScrapeEnricher:enrich:done', {
      leadId,
      tookMs: Date.now() - t0,
      chars: (iceBreaker || '').length
    });
    return {
      iceBreaker
    };
  }
  async loadLeadAndCampaign(leadId) {
    const { data: lead } = await this.supabase.from('leads').select('*').eq('id', leadId).single();
    if (!lead) throw new Error('lead not found');
    const { data: campaign } = await this.supabase.from('campaigns').select('*').eq('id', lead.campaign_id).single();
    if (!campaign) throw new Error('campaign not found');
    return {
      lead,
      campaign
    };
  }
  computeBaseAndHomepage(lead) {
    const base = (lead.company_website || '').replace(/^(https?:\/\/)?/, '');
    const homepage = `https://${base}`;
    return {
      base,
      homepage
    };
  }
  async discoverUrls(homepage) {
    let discovered = [];
    try {
      const htmlHome = await fetchHtml(homepage);
      discovered = extractInternalLinks(htmlHome, homepage);
    } catch  {}
    // Shuffle helper
    const shuffle = (arr)=>{
      for(let i = arr.length - 1; i > 0; i--){
        const j = Math.floor(Math.random() * (i + 1));
        [arr[i], arr[j]] = [
          arr[j],
          arr[i]
        ];
      }
      return arr;
    };
    const getExt = (u)=>{
      try {
        const path = new URL(u).pathname;
        const last = path.split('/').filter(Boolean).pop() || '';
        const dotIdx = last.lastIndexOf('.');
        if (dotIdx <= 0) return null;
        return last.slice(dotIdx + 1).toLowerCase();
      } catch  {
        return null;
      }
    };
    const badExt = new Set([
      'mp4',
      'mov',
      'avi',
      'mkv',
      'webm',
      'mp3',
      'wav',
      'flac',
      'pdf',
      'png',
      'jpg',
      'jpeg',
      'gif',
      'svg',
      'ico',
      'webp',
      'css',
      'js',
      'json',
      'xml',
      'zip',
      'rar',
      '7z',
      'gz',
      'tar'
    ]);
    const docExt = new Set([
      'html',
      'htm',
      'php',
      'asp',
      'aspx',
      'md',
      'txt'
    ]);
    const pool = discovered.filter(Boolean);
    shuffle(pool);
    const selected = [];
    let preferExt = null;
    for (const url of pool){
      if (selected.length >= 3) break;
      const ext = getExt(url);
      if (preferExt) {
        if (ext === preferExt) selected.push(url);
        continue;
      }
      if (!ext) {
        selected.push(url);
        continue;
      }
      if (badExt.has(ext)) {
        continue;
      }
      if (docExt.has(ext)) {
        selected.push(url);
        preferExt = ext // if we picked an extension, prefer same ext next
        ;
      }
    }
    const homeNormalized = normalizeUrl(homepage);
    const normalizedSelected = selected.map((u)=>normalizeUrl(u)).filter(Boolean);
    const urls = Array.from(new Set([
      homeNormalized,
      ...normalizedSelected
    ]));
    return urls;
  }
  async summarizeTopPages(urls, campaign, lead, base, limit) {
    const pageSummaries = [];
    const errors = [];
    for (const url of urls){
      if (pageSummaries.length >= limit) break;
      const res = await this.summarizeSingleUrl(url, campaign, lead, base);
      if (res.abstract) pageSummaries.push(`URL: ${url}\n${res.abstract}`);
      if (res.error) errors.push(res.error);
    }
    // Keep summaries we have; if none succeeded, throw the last error to surface a reason
    if (pageSummaries.length === 0 && errors.length > 0) {
      throw new Error(errors[errors.length - 1]);
    }
    return pageSummaries;
  }
  async summarizeSingleUrl(url, campaign, lead, base) {
    try {
      const html = await fetchHtml(url);
      const md = htmlToMarkdown(html);
      const template = (campaign.summarize_prompt || '').trim();
      const contentSnippet = md.slice(0, 6000);
      const prompt = template.includes('{markdown}') ? template.replace('{url}', url).replace('{markdown}', contentSnippet) : `Summarize the following webpage content from ${lead.company_name || 'the company'} (${base}). Return JSON exactly {"abstract":"..."}. If the content isn't clearly about this company/site, return {"abstract":"no content"}.\n\nURL: ${url}\n\nCONTENT START\n${contentSnippet}\nCONTENT END`;
      const sys = `You are summarizing a company's OWN webpage for LLM enrichment.\n\nRules:\n- Company: ${lead.company_name || ''}\n- Primary domain (must match): ${base}\n- URL being summarized: ${url}\n- Summarize ONLY if the content clearly pertains to THIS business (its offering/services, about, work/portfolio).\n- If the content is generic, news-like, scraped wrong, or not obviously about this company/site, output exactly: {"abstract":"no content"}.\n- Respond ONLY in JSON exactly like {"abstract":"..."}. No commentary before or after the JSON.`;
      const summary = await openAiChat(this.openaiKey, [
        {
          role: 'system',
          content: sys
        },
        {
          role: 'user',
          content: prompt
        }
      ]);
      const abstract = extractAbstract(summary);
      if (!abstract) {
        return {
          error: 'openai: invalid or non-JSON summary'
        };
      }
      return {
        abstract: abstract || 'no content'
      };
    } catch (err) {
      const msg = errToString(err);
      console.error('WebsiteScrapeEnricher:summarize:error', {
        url,
        err: msg
      });
      const category = /openai/i.test(msg) ? 'openai' : 'scrape';
      return {
        error: `${category}: ${msg}`
      };
    }
  }
  async generateIcebreaker(campaign, lead, pageSummaries) {
    const icePrompt = campaign.icebreaker_prompt.replace('{serviceLine}', campaign.service_line);
    const profile = {
      full_name: lead.full_name || [
        lead.first_name,
        lead.last_name
      ].filter(Boolean).join(' ').trim() || null,
      title: lead.title || null,
      headline: extractHeadlineFromRaw(lead.raw) || null,
      industry: lead.industry || null,
      city: lead.city || null,
      state: lead.state || lead.region || null,
      country: lead.country || null
    };
    let iceBreaker;
    try {
      iceBreaker = await openAiChat(this.openaiKey, [
        {
          role: 'system',
          content: "You're a helpful, intelligent sales assistant."
        },
        {
          role: 'assistant',
          content: "Hey Aina,\n\nLove what you're doing at Maki. Also doing some outsourcing right now, wanted to run something by you.\n\nSo I hope you'll forgive me, but I creeped you/Maki quite a bit. I know that discretion is important to you guys (or at least I'm assuming this given the part on your website about white-labelling your services) and I put something together a few months ago that I think could help. To make a long story short, it's an outreach system that uses AI to find people hiring website devs. Then pitches them with templates (actually makes them a white-labelled demo website). Costs just a few cents to run, very high converting, and I think it's in line with Maki's emphasis on scalability."
        },
        {
          role: 'user',
          content: icePrompt
        },
        {
          role: 'user',
          content: "Profile: " + JSON.stringify(profile) + "\n\nWebsite summaries: " + pageSummaries.join('\n\n')
        }
      ]);
    } catch (e) {
      const msg = errToString(e);
      console.error('WebsiteScrapeEnricher:ice:error', {
        err: msg
      });
      throw new Error(msg);
    }
    return iceBreaker;
  }
}
